This document describes the current design of Clacc, which extends
Clang and LLVM with support for OpenACC.

Design Rationale
================

This document focuses on the details of the current Clacc design and
only summarizes the design rationale.  A more complete description of
the design rationale, including a presentation of several design
alternatives that were considered, appears in sections I through II.D
of the following paper:

> Clacc: Translating OpenACC to OpenMP in Clang, Joel E. Denny, Seyong
> Lee, and Jeffrey S. Vetter, 2018 IEEE/ACM 5th Workshop on the LLVM
> Compiler Infrastructure in HPC (LLVM- HPC), Dallas, TX, USA, (2018).

High-Level Design
=================

A key feature of Clacc's design is to translate OpenACC to OpenMP in
order to build on Clang's existing OpenMP compiler and runtime
support.  Clacc performs this translation at the AST level, producing
AST representations of both the original OpenACC and the generated
OpenMP.  As such, Clacc's design is depicted abstractly in the
following figure:

```
   OpenACC source
         |
         | parser
         v
    OpenACC AST
         |
         | TransformACCToOMP
         v
    OpenMP AST
         |
         | codegen
         v
      LLVM IR
         |
         | LLVM
         v
    executable
  OpenACC runtime
   OpenMP runtime
```

The components of this diagram are as follows:

* **OpenACC source** is C application source code containing OpenACC
  constructs.  C++ will be supported in the future.  Currently,
  Fortran support is not planned and would not be based on Clang.
* **Parser** is the existing Clang parser and semantic analyzer
  extended for OpenACC.
* **OpenACC AST** is a Clang AST in which OpenACC constructs are
  represented by OpenACC node types, which are a Clacc extension to
  Clang.
* **`TransformACCToOMP`** is a new Clang component introduced by Clacc
  to transform OpenACC to OpenMP entirely at the AST level.
* **OpenMP AST** is a Clang AST in which OpenACC constructs have been
  lowered to OpenMP constructs represented by OpenMP node types, which
  exist in Clang independently of Clacc.
* **Codegen** is the existing Clang backend, which lowers the OpenMP
  AST to LLVM IR.
* **LLVM IR** is the usual LLVM intermediate representation
  generated by Clang for an OpenMP AST.
* **LLVM** consists of all LLVM optimization passes and backends that
  lower LLVM IR into object form.
* **Executable** is the final application executable.
* **OpenACC runtime** is built on top of LLVM's existing **OpenMP
  runtime** with extensions for OpenACC's run-time environment
  variables, library API, etc.

This design has a number of advantages.  First, the construction of an
OpenACC AST should facilitate the development of additional OpenACC
source-level tools, such as pretty printers, static analyzers,
lint-like tools, and debugger and editor extensions.  The construction
of an OpenMP AST should facilitate a number of non-traditional
user-level compiler features, such as automated porting of OpenACC
applications to OpenMP, and reuse of existing OpenMP tools for
OpenACC.  Because the OpenACC syntax and OpenMP syntax are so similar,
simple translations from OpenACC to OpenMP are easier to implement at
the AST level than as part of a later compiler stage.  Finally,
because the AST is the highest-level representation, implementing at
the AST level maximizes the amount of the existing OpenMP
implementation that Clacc can reuse.

It is important to understand that the above description is abstract.
Specifically, as described in the next section, `TransformACCToOMP` is
not a distinct compiler phase, and the OpenACC AST and OpenMP AST are
actually represented within a single Clang AST.

TransformACCToOMP
=================

A key issue in transforming OpenACC to OpenMP in Clang ASTs is that
Clang ASTs are designed to be immutable once constructed.  This
immutability property might at first seem to make Clacc's
`TransformACCToOMP` component impossible to implement, but it does
not.  In this section, we describe Clang's `TreeTransform` facility
and explain how `TransformACCToOMP` employs it to cleanly work around
this immutability property.

Background: TreeTransform
-------------------------

Independently of Clacc, Clang uses the `TreeTransform` facility to
transform C++ templates for the sake of instantiating them.  When the
parser reaches a template instantiation in the source code,
`TreeTransform` builds a transformed copy of the AST subtree that
represents the template, and it inserts that copy into the AST.  This
insertion is part of the normal process of extending the AST during
parsing and so does not violate AST immutability.

`TreeTransform`'s design has some convenient properties for Clacc's
purposes:

* **Extensibility**: `TreeTransform` is a class template employing the
  curiously recurring template pattern (CRTP) for static polymorphism.
  Thus, it is possible to override default behavior that is reasonable
  for C++ template instantiation but not for translation from OpenACC
  to OpenMP.
* **Encapsulation of `Sema`**: `TreeTransform`'s interface serves as a
  convenient encapsulation of semantic actions that are normally
  called during parsing.  This encapsulation enables Clacc to call
  those actions to build OpenMP ASTs without developing fragile
  dependencies on the current OpenMP implementation within `Sema`.

However, there are also some caveats to consider for `TreeTransform`:

* **Transitory semantic data**: To build new nodes, `TreeTransform`
  runs many of the same semantic actions that the parser normally
  runs.  Those semantic actions require the transitory semantic data
  that has been stored in Clang's `Sema` object by the time the parser
  reaches the syntactic context where new nodes are to be inserted,
  but the parser gradually discards some of that semantic data as the
  parser progresses to other syntactic contexts.  Thus,
  `TreeTransform` cannot be run on arbitrary nodes in the AST at
  arbitrary times.  For example, to run `TreeTransform` on arbitrary
  nodes in a translation unit after the parsing of that translation
  unit has completed, it might be necessary to transform the
  translation unit's entire AST in order to rebuild all of the
  necessary transitory semantic metadata.
* **Permanent semantic data**: Currently, parsing a C++ template
  permanently associates semantic data with that template's AST
  subtree in a way that's compatible with later runs of
  `TreeTransform` for instantiations of that template.  However,
  there's no guarantee that semantic data that is reasonable for C++
  template instantiation will be compatible with any arbitrary
  extension of `TreeTransform`.  For example, we have noticed that, if
  we write a simple `TreeTransform` extension that merely duplicates
  an OpenMP region immediately after that region's node is
  constructed, the default `TreeTransform` implementation does not
  update the declaration contexts for variable declarations that are
  local to the duplicate region (see `TreeTransform::TransformDecl`),
  so those duplicate variables appear to be declared in the original
  region, resulting in spurious compiler diagnostics.
* **Redundant AST subtrees**: As described above, `TreeTransform` is
  designed to construct modified versions of existing subtrees, and it
  is not designed to remove the original subtrees.  This behavior
  makes sense for C++ template instantiation because the original
  template must remain in the AST for additional instantiations.
  Moreover, the template and its instantiations represent distinct
  regions of the original source.  However, in the case of Clacc, an
  OpenACC subtree and the OpenMP subtree to which it is translated
  represent different versions of the same region of the source, so
  AST iterations must take special care not to visit both when they're
  expecting only one version of the source.

Design
------

Clacc's `TransformACCToOMP` component is implemented as a class
derived via CRTP from `TreeTransform`.  As mentioned earlier,
`TransformACCToOMP` does not represent a distinct compiler phase.
Instead, immediately after parsing each OpenACC region and
constructing an associated OpenACC subtree, Clacc passes the OpenACC
subtree to `TransformACCToOMP` to construct the corresponding OpenMP
subtree.  Clacc adds the resulting OpenMP subtree's root as a hidden
child of the OpenACC subtree's root, and then parsing continues.

For example, consider this function written in OpenACC, where comments
show the equivalent OpenMP:

```
void foo() {
  #pragma acc parallel  // #pragma omp target teams
  #pragma acc loop gang // #pragma omp distribute
  for (int i=0; i<2; ++i)
    // loop body
}
```

The AST that Clacc constructs is depicted below:

```
       TranslationUnit
              |
         FunctionDecl
              |
         CompoundStmt
              |
     ACCParallelDirective
              |          `-OMPNode-> OMPTargetTeamsDirective
       ACCLoopDirective                         |
            /   \      `---OMPNode---> OMPDistributeDirective
ACCGangClause   ForStmt                         |
                   |                         ForStmt
                                                |
```

Thus, the `ForStmt` node and its subtree are duplicated.  The
`ACCLoopDirective` node is translated to an `OMPDistributeDirective`
node, which becomes the normal parent for the translated `ForStmt`
node and the hidden OpenMP child for the `ACCLoopDirective` node.
Finally, the `ACCParallelDirective` is translated to an
`OMPTargetTeamsDirective` node, which becomes the normal parent for
the `OMPDistributeDirective` node and the hidden OpenMP child for the
`ACCParallelDirective` node.

Clacc overcomes the `TreeTransform` caveats discussed in the previous
section as follows:

* **Transitory semantic data**: Because Clacc calls
  `TransformACCToOMP` immediately after constructing an OpenACC
  subtree, the exact transitory semantic data needed to construct the
  corresponding OpenMP subtree is present.
* **Permanent semantic data**: So far, Clacc is able to override
  specific `TreeTransform` functionality in order to transform
  semantic data that would be permanent across C++ template
  instantiation but that must be different between OpenACC and OpenMP
  subtrees.
* **Redundant AST subtrees**: AST traversals are typically based on
  Clang's `RecursiveASTVisitor` facility.  Most AST traversal
  developers and users likely expect for traversals to visit an AST
  representing the original source code only.  Because the OpenMP node
  to which an OpenACC node is translated is not recorded as a normal
  child of the OpenACC node, `RecursiveASTVisitor` visits the OpenACC
  node but skips its hidden OpenMP child.  However, while visiting an
  OpenACC node, a visitor can be written to call the node's
  `getOMPNode` member function to access the OpenMP node, possibly for
  a recursive visitation.

As a result, Clacc supports at least three kinds of AST traversals:

* **Visit OpenACC only**: For example, `-ast-print` is an existing
  Clang command-line option for translating the Clang AST back to
  source.  Because the output of `-ast-print` has thus always
  corresponded to the original preprocessed input and never a lowered
  version of it, Clacc extends it for OpenACC not to include the
  OpenMP translation.  In the previous example, `-ast-print` thus
  visits the `ACCParallelDirective` node, the `ACCLoopDirective` node,
  and the original `ForStmt` subtree but not the
  `OMPTargetTeamsDirective` node, the `OMPDistributeDirective` node,
  or the translated `ForStmt` subtree.
* **Delegate to OpenMP**: For example, one of the major motivations
  for translating the OpenACC AST to an OpenMP AST is to reuse the
  existing LLVM IR codegen implementation for OpenMP.  Thus, for LLVM
  IR codegen, each OpenACC node delegates to its hidden OpenMP child.
  In the previous example, the `ACCParallelDirective` node delegates
  LLVM IR codegen to the `OMPTargetTeamsDirective` node and its
  subtree, and the normal subtree of the `ACCParallelDirective` node
  is not visited.
* **Visit OpenACC and OpenMP**: For example, `-ast-dump` is an
  existing Clang command-line option for printing a textual
  representation of the AST structure, including parent-child
  relationships, source location information, and computed types.
  This feature is clearly designed for debugging ASTs and is very
  useful for Clang developers.  For each OpenACC AST node, Clacc
  extends this feature to always produce a full representation of that
  node's subtree including, as a specially marked child, the OpenMP
  subtree to which it translates.

Redundant AST subtrees might at first seem to be a disadvantage of
employing `TreeTransform` in `TransformACCToOMP`.  However, because it
results in a representation of the chosen mapping from OpenACC to
OpenMP, we believe it augments the potential for constructing flexible
debugging and analysis tools on top of Clacc.  The capabilities of
`-ast-dump`, as described above, and `-fopenacc-print`, as described
in the next section, are simple examples.

Codegen
=======

As mentioned in the previous section, an OpenACC AST node implements
LLVM IR codegen by delegating to its hidden OpenMP child.  The most
obvious points for this implementation are the OpenACC cases in the
main switch on AST node types within Clang codegen's
`CodeGenFunction::EmitStmt`.

While necessary, those implementation points are insufficient for
offloading support.  The trouble is that the OpenMP codegen
implementation also has a hook into Clang's codegen framework outside
that switch.  This hook calls
`CGOpenMPRuntime::scanForTargetRegionsFunctions`, which recurses
through AST nodes looking for OpenMP target regions to emit in
separate device functions.  Thus, Clacc extends this scan to look for
OpenACC AST nodes and, as before, to delegate the required codegen to
their hidden OpenMP children.

Source-to-Source Translation
============================

The `TransformACCToOMP` section described how Clacc uses Clang's
`TreeTransform` facility to construct and attach hidden OpenMP
subtrees to OpenACC subtrees.  It also mentions that `-ast-print`
prints only OpenACC.  In this section, we describe Clang's `Rewrite`
facility, which is normally used in Clang for source-to-source
translation, and we describe how Clacc prints OpenMP source.

Background: Rewrite
-------------------

The `Rewrite` facility in Clang is used in tools like `clang-format`
and `clang-tidy` to perform source-to-source translation.  However,
`Rewrite` does not perform AST transformations.  Instead, `Rewrite`
provides an API for making textual modifications to Clang's input
buffer, which contains the original input source code, while using the
Clang AST to guide those modifications.

To produce a transformed AST, the transformed source from `Rewrite`
must be parsed anew by Clang to construct an entirely separate AST.
For this reason, `Rewrite` is most useful for implementing a single
transformation pass whose output is source.  `Rewrite` is not
efficient for successive transformation passes or for LLVM IR codegen.
Direct AST transformations are better for those purposes.

Because traditional OpenACC compilation is a major use case for Clacc,
and because for Clang that requires LLVM IR codegen, we chose
`TreeTransform` not `Rewrite` to implement `TransformACCToOMP`.
However, source-to-source translation is also a Clacc use case, and,
as discussed in the next section, `Rewrite` is helpful there after
`TransformACCToOMP`.

Design
------

To enable source-to-source translation from the Clang command line,
Clacc supports two new Clang command-line options: `-fopenacc-print`,
which is built on `Rewrite`, and `-fopenacc-ast-print`, which is built
on `-ast-print`.  Each takes any of the following values:

* `acc`: OpenACC constructs are printed and the OpenMP constructs to
  which they were translated are ignored.  Thus, this value is likely
  not helpful to users but can be helpful to developers for debugging
  the Clacc implementation.  That is, `-fopenacc-print=acc` merely
  prints the original source without modification, and
  `-fopenacc-ast-print=acc` is a more convenient form of `-Xclang
  -ast-print -fsyntax-only -fopenacc`.
* `omp`: OpenMP constructs are printed, and the OpenACC constructs
  from which they were translated are ignored.
* `acc-omp`: OpenACC constructs are printed and the OpenMP constructs
  to which they were translated are printed in neighboring comments.
* `omp-acc`: OpenMP constructs are printed and the OpenACC constructs
  from which they were translated are printed in neighboring comments.

In the last two cases, Clacc will avoid duplicating the code block
associated with a directive if that code block prints identically in
both the OpenACC and OpenMP versions.  The output then looks similar
to the code passage in the previous example.

Originally, Clacc only supported the functionality of
`-fopenacc-ast-print` (but under a different name).  Because it's
built on `-ast-print`, its functionality is problematic in several
ways:

* `-ast-print` was designed for debugging and not for faithful
  printing of the AST.  Even so, we have successfully contributed
  upstream a number of fixes to improve the fidelity of its output on
  the grounds that such fixes also improve the debugging use case.
  Still, our hunch is that there is likely much more work to do,
  especially in the case of C++ as we have mostly focused on C so far.
* Because `-ast-print` computes its output from the AST structure, the
  output looks like the output of Clang's preprocessor.  Thus,
  includes and other macros are expanded, and the original formatting
  and comments are lost.  Such mangling of the source is unsuitable
  for permanent migration of an application from OpenACC to OpenMP.
  It's also unsuitable when targeting a different OpenMP compiler
  perhaps for a different target architecture where preprocessor
  macros and includes expand differently.

On the other hand, because `-fopenacc-print` is built on `Rewrite`, it
modifies the original input buffer and thus can avoid these problems
in most cases.  That is, `-fopenacc-print` examines the OpenACC
subtrees and the OpenMP subtrees computed by `TransformatACCToOMP` as
needed to modify the input buffer in the manner requested by the
argument to `-fopenacc-print`.  For OpenMP subtrees containing
directives and other code not appearing in the original source and
thus not in the input buffer, it still employs `-ast-print`
functionality, but at least the above problems are not pervasive in
the output.  In the future, we might experiment with using some means
such as source locations to track which portions of an OpenMP subtree
were copied verbatim from the OpenACC subtree and then overriding
`-ast-print` functionality to print just those portions using the
original input buffer.

Interaction with OpenMP Support
===============================

`-fopenmp`
----------

Even though Clacc translates OpenACC to OpenMP, Clacc currently does
not support OpenACC and OpenMP in the same source.  Doing so would
require, for example, extensions to data sharing analyses to consider
the interactions between OpenACC and OpenMP directives and clauses.
Thus, Clacc reports an error diagnostic if `-fopenmp` is specified on
the Clang command line when OpenACC support is enabled by any
`-fopenacc*` option.  To implement this, Clacc extends the Clang
driver to just pass the relevant command-line options to the Clang
front end, and it extends the front end to produce the error
diagnostic.  Thus, specifying `-cc1` to bypass the driver does not
avoid the error diagnostic.

Discarding OpenMP (`-Wsource-uses-openmp`)
------------------------------------------

As usual when `-fopenmp` is not specified, the front end discards
OpenMP directives in the source during parsing, and
`-Wsource-uses-openmp` is available as usual to request warnings about
them.  Nevertheless, Clacc must enable OpenMP support in the front end
in order to build OpenMP subtrees without failing many assertions in
the OpenMP implementation, but enabling OpenMP support normally
prevents OpenMP directives from being discarded.  To implement all
this, Clacc extends the front end in two ways: (1) after confirming
the user did not request both OpenACC and OpenMP support, it enables
OpenMP support if OpenACC support is enabled, and (2) it discards
OpenMP directives during parsing if either OpenMP support is disabled
or OpenACC support is enabled.

`-fopenmp-*`
------------

Clacc permits all `-fopenmp-*` command-line options when OpenACC
support is enabled.  These options adjust various OpenMP features when
compiling the OpenMP translation.  To implement this, Clacc extends
Clang to check if OpenACC support is enabled everywhere it already
checks if OpenMP support is enabled.  However, so far, only
`-fopenmp-targets=<triples>` to specify desired offloading targets has
been tested, and it's only been tested for traditional compilation
mode.

It's not clear if `-fopenmp-*` options should be relevant to
source-to-source mode.  First, some options like
`-fopenmp-targets=<triples>` affect the OpenMP version Clang selects
by default, and that can affect semantics, diagnostics, and any
AST-printed code containing `_OPENMP`, but should Clacc let any of
that matter when compiling OpenACC?  Second, in experimental
implementations, we have observed that `-fopenmp-targets=nvptx64` adds
many declarations to the source code printed for `nvptx64`.  Would
offload bundling of the various versions of the source code be useful?

In general, the Clacc user should not have to be aware that OpenMP
support is being utilized when in traditional compilation mode.
However, the need to combine `-fopenmp-targets=<triples>` with
`-fopenacc` to enable offloading, for example, violates that
principle.  Moreover, diagnostics for `-fopenmp-*` are currently
expressed in terms of OpenMP even when OpenACC support is enabled.  In
the future, especially when Clacc is considered for upstreaming, Clacc
might develop its own `-fopenacc-*` options to be used instead.
Nevertheless, for now, we have concluded that the Clacc implementation
will be easier to keep in sync with upstream while the Clacc
implementation reuses the existing `-fopenmp-*` options with minimal
modifications.

`-fopenmp=<lib>`
----------------

Normally, `-fopenmp=<lib>` can be used to specify an alternate OpenMP
library.  However, Clang handles it as an alias for `-fopenmp`, so
it's also expected to enable OpenMP support.  We feel it would be
subtle and surprising to users if Clacc were to suppress the latter
behavior when OpenACC support is enabled, so it is currently not
possible to use `-fopenmp=<lib>` to specify an alternate OpenMP
library when OpenACC support is enabled.  Options like `-L` and `-l`
must be used instead.

OpenACC to OpenMP Mapping
=========================

This section details Clacc's planned mapping from OpenACC directives
and clauses to OpenMP directives and clauses.  If an OpenACC directive
or clause does not appear in this section, we haven't planned it yet.
`README-OpenACC-status.md` lists which OpenACC directives and clauses
Clacc already implements.

Notation
--------

For conciseness, we use the following notation when describing clauses
and data attributes:

* *pre* labels a data attribute that is predetermined by the compiler
  (that is, cannot be overridden by an explicit clause) and is not
  specified by an explicit clause.
* *imp* labels a data attribute that is implicitly determined by the
  compiler (that is, can be overridden by an explicit clause) and is
  not specified by an explicit clause.
* *exp* labels a clause, possibly specifying a data attribute, that is
  explicitly specified in the source.
* *not* labels a clause that is not explicitly specified.
* The notation *L C* -> *L' C'* specifies that clause or data
  attribute *C* under the condition identified by label *L* maps to
  clause or data attribute *C'* under the condition identified by
  label *L'*, where a label is *pre*, *imp*, *exp*, or *not*.
* The notation *L*|*L' C* -> *L'' C'* specifies both of the following
  mappings:
    * *L C* -> *L'' C'*
    * *L' C* -> *L'' C'*
* Mappings for per-variable data attributes and clauses are per
  variable and per directive.
* Mappings for other clauses are per directive.
* Where arguments to clauses are not specified on either end of the
  mapping, the mapping maintains the arguments as they are even if the
  clause name or position changes.

Prescriptive vs. Descriptive OpenACC
------------------------------------

The mapping in this section represents a conservative choice intended
to always achieve correct OpenACC behavior.  As Clacc evolves to
support a descriptive interpretation of OpenACC and the requisite
compiler analyses, this mapping will represent the base choice from
which Clacc will look for deviations to improve performance of the
application, and this mapping will represent the fall back choice if
Clacc fails to find better mappings.  Under Clacc's current
prescriptive interpretation of OpenACC, Clacc supports no such
analyses and so effectively always falls back to this mapping.

Explicit vs. Implicit OpenMP Clauses
------------------------------------

One theme throughout Clacc's mapping is that Clacc does not rely on
implicit or predetermined attributes of OpenMP except for cases where
an explicit clause is not permitted or is difficult to produce.  That
is, Clacc tries to make the exact behavior it intends to produce as
explicit as possible in the generated OpenMP for the sake of
debugging. Thus, -> *exp* appears frequently below.

Semantic Clarifications
-----------------------

While developing this mapping, we found we had to make assumptions
about a number of aspects of OpenACC semantics in C that are not clear
in the OpenACC specification.  In many cases, it was the related
behavior of the Clang OpenMP implementation that brought the need for
those assumptions to our attention.  We describe those assumptions in
this section.

### Basic Data Sharing ###

* It is an error if a variable has more than one of *exp*
  `firstprivate`, *exp* `private`, or *exp* `reduction` on an OpenACC
  directive.  Notes:
    * These have contradictory specifications for initialization of
      the local copy of the variable.
    * Relative to `firstprivate` and `private`, `reduction` has a
      contradictory specification for storing data back to the
      original variable.
* While OpenACC does not define a `shared` clause, Clacc assigns the
  OpenMP *imp* `shared` semantics to any variable that is referenced
  within an OpenACC construct and declared outside it and for which
  OpenACC semantics do not specify `firstprivate`, `private`, or
  `reduction`.
    * TODO: This really doesn't make sense for `omp distribute`
      because a team-private variable cannot become team-shared at the
      `omp distribute`.  It probably doesn't make sense for `omp
      simd`, which doesn't permit `shared` either.  Anyway, as noted
      in the mappings below, Clacc relies on implicit data sharing
      there because *exp* `shared` isn't permitted, so the
      implementation seems right, but our description here seems
      misleading.
* *exp* `firstprivate`, *exp* `private`, or *exp* `reduction` for a
  variable of incomplete type is an error.  Notes:
    * A local copy must be allocated in each of these cases, but
      allocation is impossible for incomplete types.
* *exp* `private` or *exp* `reduction` for a `const` variable is an
  error.  Notes:
    * The local copy of a `const` private variable would remain
      uninitialized throughout its lifetime.
    * A reduction assigns to both the original variable and a local
      copy after its initialization, but `const` prevents that.
    * `firstprivate` is fine for a `const` variable.  The local copy
      will have the original variable's value throughout its lifetime.

### Reductions ###

* Given some variable *v*, rules to assign *imp* `shared(`*v*`)` or
  *imp* `firstprivate(`*v*`)` on an `acc parallel` directive are
  ignored if the following rule would then produce an *imp*
  `reduction` for *v* on that `acc parallel`.  Notes:
    * In our experiments, both gcc 7.3.0 and pgcc 18.10-0 perform a
      gang reduction as described in this rule and the following rule
      when *v* is *imp* `firstprivate`, but OpenACC 2.7 sec. 2.9.11
      L1569-1573 says there is no gang reduction for private
      variables.  However, that text is confusing in multiple ways, so
      Clacc just follows pgcc and gcc behavior.
* Given some variable *v* that is declared outside an `acc parallel`,
  if (1) neither *exp* `firstprivate(`*v*`)` nor *exp*
  `private(`*v*`)` on that `acc parallel`, and (2) *exp*
  `reduction(`*o*`:`*v*`)` on any nested gang-partitioned `acc loop`,
  then this `acc parallel` has *imp* `reduction(`*o*`:`*v*`)`.  Notes:
    * If the first condition doesn't hold but the second does, then
      the reduction refers to the gang-private copy of *v*, so no
      gang-reduction is implied.  In our experiments, gcc 7.3.0 and
      pgcc 18.4-0 also appear to have this behavior.
* It is an error if, on a particular OpenACC directive, there exist
  multiple *imp|exp* `reduction` with different reduction operators
  for a single variable *v*.
    * OpenACC 2.7 sec. 2.9.11 L1580-1581 specifies this restriction
      for *exp* `reduction` on nested constructs, but it doesn't
      discuss the case where sibling `acc loop` constructs specify
      conflicting gang reductions.
* Variable type restrictions for `reduction` are specified in
  `README-OpenACC-status.md` as that is a highly user-visible issue.

### Integer Expression Arguments ###

* It is an error if an argument to `num_gangs`, `num_workers`, or
  `vector_length` is not a positive integer expression.  If the
  argument to `vector_length` is not also a constant expression, Clacc
  does not use it and reports a warning diagnostic.  See
  `README-OpenACC-status.md` for rationale.

### Loop Control Variables ###

* For an `acc loop` directive with *exp* `seq` such that the loop
  control variable is just assigned instead of declared in the init of
  the attached `for` loop, the loop control variable is *imp*
  `shared`.  Notes:
    * Otherwise, there appears to be no way to tell an aggressive
      OpenACC compiler to leave such a loop as a normal sequential
      loop in C, where the variable would normally have `shared`
      semantics in that its final value is visible after the loop.
    * OpenACC 2.7 sec. 2.6.1 L876-879 only requires that the variable
      is private to each thread executing the loop.  Only one thread
      executes a sequential loop, and it's the same thread that
      executes outside the loop.  The specification does not appear to
      clarify whether the variable's privacy is also limited to the
      loop's region.  Clacc uses the interpretation that, as explained
      above, seems more useful.
    * In our experiments, this choice is consistent with pgcc 19.4-0,
      but gcc 8.3.0 assumes *pre* `private` instead.
* For any other `acc loop` directive, the loop control variable is
  *pre* `private`.  Notes:
    * OpenACC 2.7 sec. 2.6.1 L876-879 only requires that the variable
      is private to each thread executing the loop.  Clacc interprets
      this as *pre* `private`, which additionally means none of those
      private variables are visible after the loop.
    * This choice is not consistent with the previous case.  However,
      because the deciding factors are the presence of *exp* `seq` and
      whether the loop control variable is declared or just assigned,
      it is straight-forward for the OpenACC programmer to determine
      the visibility of the loop control variable without, for
      example, predicting the compiler's parallelization decisions.
    * In our experiments, this choice is consistent with gcc 8.3.0.
      However, pgcc 19.4-0 appears to let each thread (within each
      gang within each worker) retain the value it would have after
      incrementing once past only the iterations it performs, so the
      value visible afterward depends on the exact partitioning and
      which thread is the master and thus continues to run after the
      loop.  Thus, pgcc seems the most consistent with the exact
      wording in the spec.
    * This choice is consistent with OpenMP 4.5's choice for
      `distribute` (`gang`) and `parallel for` (`worker`)
      (sec. 2.15.1.1 p. 179 lines 24-25).
    * This choice is not consistent with OpenMP 4.5's choice for
      `simd` (`vector`) (sec. 2.15.1.1 p. 179 lines 26-27), which
      instead specifies pre `linear`, which has `lastprivate`-like
      semantics.
    * This choice is reasonably straight-forward to translate to
      OpenMP, but the pgcc approach would be harder to translate to
      OpenMP.  For example, in our experiments, `lastprivate` produces
      either the original value from before the loop or the value
      after the entire loop and not the value after only the
      iterations performed by the thread.
    * It is not clear whether the values produced by the pgcc approach
      are actually useful given their dependence on the exact
      partitioning chosen by the compiler.
* For any `acc loop` directive, *exp* `reduction` is not permitted on
  a loop control variable regardless of its data sharing.  Notes:
    * For consistency with parallelized `acc loop` directives, this
      rule applies for sequential `acc loop` directives even
      though the mapping for them discards the `reduction`.
    * If the loop control variable is declared instead of just
      assigned in the init of the attached `for` loop, any reference
      to the variable's name in the directive's clauses refers to a
      different variable, so this rule does not apply.
    * Clang's OpenMP implementation also enforces this constraint.
      That makes sense by the OpenMP spec because an OpenMP
      `reduction` is a data sharing attribute and a loop control
      variable has a different predetermined data sharing attribute.
    * For OpenACC, gcc 7.2.0 also enforces this constraint, but pgcc
      18.4-0 does not enforce it.

### Implicit Gang Clauses ###

The OpenACC technical committee has discussed [clarifying the behavior
of *naked* loop
directives](https://github.com/OpenACC/openacc-spec/issues/125).  In
these discussions, a naked loop directive is an `acc loop` directive
with *not* `seq`, *not* `gang`, *not* `worker`, and *not* `vector`.
The problem is that the OpenACC spec implies that such a loop should
run in gang-redundant mode, but existing OpenACC compilers (GCC and
PGI) usually gang-partition it.  The difference between these modes is
often important to semantic correctness besides just performance, and
understandably some existing OpenACC programs were written to expect
the semantics that existing compilers provide.  This issue has not yet
been resolved as of OpenACC 2.7.

Clacc attempts to mimic the behavior of existing OpenACC compilers by
adding *imp* `gang` to `acc loop` directives, but many questions
remain about exactly how *imp* `gang` placement should be computed.
Currently, it works as follows in Clacc:

* Any conversion of `acc loop` constructs with *exp* `auto` to
  sequential loops is performed before computing *imp* `gang`
  placement.  Notes:
    * Currently, Clacc converts all `acc loop` constructs with *exp*
      `auto` to sequential loops.  Obviously, as Clacc grows a
      descriptive interpretation of `auto`, some such constructs will
      be handled as if they have *imp* `independent` instead.
    * Performing `auto` conversions first so that *imp* `gang`
      placement depends on them places more optimization power in the
      hands of the compiler.  For example, in an `acc loop auto` nest,
      the compiler could choose any loop level for gang partitioning.
      However, the difference between gang-partitioned mode and
      gang-redundant mode can have an important impact on the
      semantics of a program.  The OpenACC programmer specified `auto`
      presumably because he cannot predict the outcome of `auto`
      conversions, and thus now he cannot predict at which of the many
      loop levels these semantics will shift.
    * Performing *imp* `gang` placement first so it does not depend on
      the outcome of `auto` conversions can reduce the possible
      semantics of an OpenACC program.  In the `acc loop auto` nest
      example, the loop nest would be either entirely gang-redundant
      or entirely gang-partitioned.
    * TODO: In our experiments so far, we have not been able to
      determine what approach pgcc 19.4-0 follows generally, and it's
      not clear what's really better here.  As the OpenACC technical
      committee standardizes an approach, we will adjust Clacc.
* Within that context, an `acc loop` construct has *imp* `gang` if all
  of the following are true:
    * *not* `gang`, *not* `worker`, and *not* `vector`.  Notes:
        * The goal here is to give the OpenACC programmer some means
          to specify partitioning exactly as he sees fit.
        * Interestingly, without this constraint, it would be
          impossible to specify gang-redundant mode combined with
          worker-partitioned or vector-partitioned mode.
    * *exp* `gang` would be permitted.  Notes:
        * Based on OpenACC 2.7, *exp* `gang` would not be permitted on
          any `acc loop` construct that has (a) an ancestor `acc loop`
          construct with *exp* `gang`, *exp* `worker`, or *exp*
          `vector`, (b) *exp* `seq`, or (c) a nested `acc loop`
          construct with *exp* `gang`.
        * These restrictions are relaxed a bit for *imp* `gang`
          because `auto` conversions are performed first.  For
          example, an `acc loop auto gang` that becomes a sequential
          loop prevents a nested `acc loop` from having an *exp*
          `gang` clause but not from having an *imp* `gang` clause.
          TODO: This behavior seems inconsistent.  Should we change
          it?  In general, the semantics of `auto` plus `gang` are
          still being clarified by the OpenACC technical committee.
    * There is no ancestor `acc loop` construct that is permitted to
      have *exp* `gang`.  Notes:
        * The point here is to chose the outermost construct possible.

Parallel Directives
-------------------

Clacc's current mapping of an `acc parallel` directive and its clauses
to OpenMP is as follows:

* `acc parallel` -> `omp target teams`
* *imp* `shared` -> *exp* `shared`
* *imp*|*exp* `firstprivate` -> *exp* `firstprivate`
* *exp* `private` -> *exp* `private`
* *imp*|*exp* `reduction` -> *exp* `reduction`
* *exp* `num_gangs` -> *exp* `num_teams`
* If *exp* `num_workers` with a non-constant-expression argument, and
  if there is a nested worker-partitioned `acc loop`, then *exp*
  `num_workers` -> wrap the `omp target teams` in a compound statement
  and declare a local `const` variable with the same type and value as
  the *exp* `num_workers` argument.
* Else if *exp* `num_workers` with a non-constant-expression argument
  that potentially has side effects, then *exp* `num_workers` -> wrap
  the `omp target teams` in a compound statement and insert a
  statement that casts the argument's expression to `void`.
* Else, translation discards *exp* `num_workers`.  Notes:
    * A constant-expression argument here might be used by a nested
      worker-partitioned `acc loop`.
* If *exp* `vector_length` with a non-constant-expression argument
  that potentially has side effects, then *exp* `vector_length` ->
  wrap the `omp target teams` in a compound statement and insert a
  statement that casts the argument's expression to `void`.  Moreover,
  report a warning diagnostic that `vector_length` is being ignored.
* Else, translation discards *exp* `vector_length`.  Notes:
    * A constant expression argument here might be used by a nested
      vector-partitioned `acc loop`, but a non-constant-expression
      argument is not (this follows "Semantic Clarifications" above).

Loop Directives
---------------

Clacc does not yet support the `acc kernels` directive or an orphaned
`acc loop` directive, so an `acc loop` directive must appear in an
`acc parallel` directive.

### Sequential Loops ###

Clacc treats an `acc loop` directive as sequential if any of the
following are true:

* *exp* `seq`
* *exp* `auto`
* *not* `gang`, *not* `worker`, *not* `vector`, and not *imp* `gang`
* Notes:
    * The latter two cases normally depend on the OpenACC compiler to
      determine the best way to parallelize the loop.  Again, Clacc
      does not yet support the necessary analyses and so depends on
      the application developer to prescribe the parallelization, so
      Clacc makes the conservative choice of a sequential loop
      instead.
    * The third case (without the other two) would certainly be the
      more straightforward case to improve because OpenACC specifies
      that the loop iterations are then required to be
      data-independent (that is, *imp*|*exp* `independent`).  This is
      a case where a simple AST-level analysis could go a long way for
      existing OpenACC applications that expect a descriptive
      interpretation: Clacc could add whichever of `worker` or
      `vector` doesn't conflict with other clauses on ancestor or
      nested loops.
    * Actually, the placement of *imp* `gang` is already a step in
      this direction.  Unlike an *imp* `worker` or *imp* `vector`,
      it's necessitated due to the shift in semantics between
      gang-redundant and gang-partitioned mode, and it will likely be
      specified more exactly by the OpenACC standard in the future.
      See "Implicit Gang Clauses" above for details.

Clacc's current mapping of a sequential `acc loop` directive and its
clauses to OpenMP is as follows:

* Translation discards the `acc loop` directive and the following
  clauses or attributes:
    * *exp* `seq`, *exp* `independent`, *exp* `auto`
    * *exp* `gang`, *exp* `worker`, *exp* `vector`
    * *exp* `collapse`
    * *pre* `private` for a loop control variable that is declared in
      the init of the attached `for` loop
    * *imp* `shared`, *exp* `reduction`
    * Notes:
        * For a loop control variable that is declared in the init of
          the attached `for` loop, a private copy is already made for
          the one thread executing the loop.
        * *imp* `shared` is only for variables referenced within the
          loop but declared outside the loop, and these are already
          shared by the simple C `for` loop.
        * *exp* `reduction` reduces across only one thread because
          this is a sequential `acc loop`.  Thus, the `reduction`
          should specify the creation of a single private copy of the
          variable that is initialized and later merged back to the
          original variable according the reduction operator.  The
          only way that behavior appears to be different than just
          discarding the `reduction`, as Clacc does, is if either (1)
          the loop body performs an operation on the variable that's
          inconsistent with the reduction operator, or (2) there's a
          race on writes to the original variable that's somehow
          avoided when postponing the write to the exit of the loop.
          Clacc makes the assumption that these are likely broken use
          cases and need not be supported.  In general, it seems
          intuitive that a reduction on a sequential loop should have
          no effect.
* Otherwise, *pre*|*exp* `private` -> wrap the loop in a compound
  statement and declare an uninitialized local copy of the variable.
  Notes:
    * exp `private` just needs to be local to the one thread executing
      the loop, and so creating a new local variable is sufficient.

A sequential `acc loop` directive is gang-redundant, worker-single,
vector-single mode.  Thus, as far as partitioning is concerned, simple
C `for` loops are sufficient.  We considered mapping instead to
various OpenMP directives so that `private` and `reduction` clauses
could simply be translated to OpenMP clauses.  To understand the
desired properties of the chosen mapping described above, it's
important to understand why each of those considered mappings would
fail to behave correctly:

* `omp parallel for num_threads(1)` does not behave as a sequential
  loop in at least two ways:
    * It makes the loop control variable *pre* `private`, but that's
      not how Clacc treats an `acc loop seq` directive's loop control
      variable that is assigned but not declared in the init of the
      attached `for` loop.
    * When the loop control variable is modified in the body of the
      loop, behavior is not defined because the init, cond, and incr
      expressions alone must determine the number of iterations.  In
      our experiments, the current Clang OpenMP implementation
      observes only those expressions and ignores even the simplest
      modification in the body.  OpenACC 2.7 sec. 2.9 L1438-1439
      describes the related OpenACC requirement, which does not apply
      in the case of `seq`, so the mapping shouldn't impose this
      restriction.
* `omp parallel num_threads(1)` (drops the `for` from the above
  directive) avoids the above problems.  However, for either mapping,
  `acc loop seq` couldn't enclose an `acc loop gang` or be nested
  within an `acc loop vector` because `omp parallel` cannot enclose an
  `omp distribute` or be nested within an `omp simd`.

### Parallelized Loops ###

If Clacc does not treat an `acc loop` directive as sequential as
described in the previous section, then it treats it as parallelized.
In that case, Clacc's current mapping of the `acc loop` directive and
its clauses to OpenMP is as follows:

* `acc loop` -> `omp`
* *imp*|*exp* `gang` -> `distribute`
* *exp* `worker` -> `parallel for`
* If neither this nor any ancestor `acc loop` is gang-partitioned or
  worker-partitioned, then -> `parallel for` and -> *exp*
  `num_threads(1)`.  Notes:
    * We add `parallel for` for this case because OpenMP does not
      permit `omp simd` directly inside `omp target teams`.
    * An alternative might be to translate to `omp simd` directly
      inside `omp parallel`, but OpenMP does not have a combined `omp
      parallel simd` directive, leading us to question the semantics.
* *exp* `vector` -> `simd`
* The output `distribute`, `parallel for`, and `simd` OpenMP directive
  components are sorted in the above order before all clauses,
  including the above `num_threads(1)`, regardless of the input clause
  order.
* If *exp* `worker`, then *exp* `num_workers` from ancestor `acc
  parallel` -> *exp* `num_threads` where the argument is either (1)
  the original *exp* `num_workers` argument if it is a constant
  expression or (2) otherwise an expression containing only a
  reference to the local `const` variable generated for that *exp*
  `num_workers`.  Notes:
    * For the ancestor `acc parallel` and for all OpenACC directives
      nested between it and this `acc loop`, Clacc leaves the OpenMP
      data sharing attribute for the local `const` variable for
      `num_workers` as implicit.  Because the variable is `const`,
      private copies are not useful, so sharing is probably most
      efficient, but not all OpenMP directives permit an *exp*
      `shared` clause.  Thus, relying on implicit data sharing
      attributes throughout simplifies the implementation.
* If *exp* `vector`, then *exp* `vector_length` with a
  constant-expression argument from ancestor `acc parallel` -> *exp*
  `simdlen`.
* `collapse` -> `collapse`
* If *exp* `worker` or if this and every ancestor `acc loop` until the
  ancestor `acc parallel` is not gang-partitioned and not
  worker-partitioned, then *imp* `shared` -> *exp* `shared`.
* Else, *imp* `shared` -> *imp* `shared`.  Notes:
    * This case must map to *imp* `shared` because `omp distribute` or
      `omp simd` without `parallel for` (which Clacc adds for `worker`
      or to be able to nest `omp simd` directly within `omp target
      teams`) does not support a `shared` clause, so we must rely on
      OpenMP implicit data sharing rules then.
* *pre* `private` for a loop control variable that is declared in the
  init of the attached `for` loop -> *pre* `private`.  Notes:
    * Mapping to *exp* `private` would be erroneous because it would
      refer to a variable from the enclosing scope.
* If *exp* `vector` and the loop control variable is just assigned
  instead of declared in the init of the attached `for` loop, then
  *pre*|*exp* `private` for that variable -> *pre* `linear`.  Then,
  wrap the `omp simd` in a compound statement, and declare an
  uninitialized local copy of the loop control variable.  Notes:
    * For `omp simd`, OpenMP 4.5 specifies *pre* `linear` here
      (sec. 2.15.1.1 p. 179 lines 26-27), so we cannot translate to
      *exp* `private`.
    * Clacc doesn't attempt to map to *exp* `linear` because (1) the
      OpenMP spec says the step must be the increment from the
      attached loop, (2) the OpenMP spec says the default step for an
      *exp* `linear` is 1, and (3) we don't want to have to implement
      extracting the increment from the attached loop when we can just
      rely on the behavior of *pre* `linear` and thus on Clang's or
      some other target compiler's OpenMP implementation to extract it
      for us.
* In all other cases, *pre*|*exp* `private` -> *exp* `private`.
* If *exp* `worker` or *exp* `vector`, then *exp* `reduction` -> *exp*
  `reduction`.
* Else, translation discards *exp* `reduction`.  Notes:
    * A gang reduction for a gang-private variable is useless and so
      is discarded during translation.
    * Gang reductions for other variables are also discarded here but
      are addressed in the data sharing semantics on `acc parallel`.

Combined Directives
-------------------

The only combined OpenACC directive Clacc supports so far is `acc
parallel loop`, which is translated in two stages:

* **Translate from the combined OpenACC directive to effective
  separate directives**: Clacc performs this stage during the parse
  while constructing the `acc parallel loop` directive's AST node.
  Clacc builds the effective AST subtree containing the `acc parallel`
  and `acc loop` directives, and then it records the AST subtree for
  the outermost of those directives, `acc parallel`, as a hidden
  subtree of the `acc parallel loop` node.  The associated code block
  for the `acc parallel loop` node is recorded like a normal AST child
  for each of the `acc parallel loop` node and the `acc loop` node.
* **Translate from effective separate directives to OpenMP
  directives**: This stage is performed by `TransformACCToOMP` just as
  it normally would be for the separate directives.  That is, the `acc
  parallel loop` node delegates to the `acc parallel` node.

The relationship between the `acc parallel loop` node and the `acc
parallel` node is similar to the relationship between any non-combined
OpenACC directive's node and its OpenMP node.  Moreover, it
effectively replaces that relationship.  That is, most AST traversals,
including `-ast-print`, visit the `acc parallel loop` node and skip
over the hidden subtree for its effective `acc parallel` directive
because the `acc parallel loop` node without the `acc parallel`
subtree represents the original source.  The `-ast-dump` facility
prints the `acc parallel` node as a specially marked child node, which
prints its OpenMP node as a specially marked child node.  For codegen
to LLVM IR, the `acc parallel loop` node delegates to its effective
`acc parallel` node, which delegates to its OpenMP node.

Because the second stage of translation above is delegated to the
effective `acc parallel` directive, `acc parallel loop` does not
require a mapping to OpenMP.  However, it and its clauses do require a
mapping to its effective directives for the sake of the first stage,
as follows:

* `acc parallel loop` -> `acc parallel`, whose associated code block
  is an `acc loop`, whose associated code block is the associated code
  block from the `acc parallel loop`.
* *exp* `private` -> *exp* `private` on the effective `acc loop`.
* *exp* `reduction` -> *exp* `reduction` on each of the effective
  `acc parallel` and `acc loop`.
* Each remaining explicit clause is permitted on only one of the
  separate OpenACC directives, and so it is mapped to that directive.
* Predetermined and implicit attributes do not require a mapping to
  the effective directives because there are none because semantic
  analysis computes them only on the effective directives.

The choice to map `reduction` to the effective `acc parallel` in
addition to the effective `acc loop` doesn't follow the OpenACC 2.6
specification.  However, strictly speaking, OpenACC 2.6 specifies
reductions are only for scalars, which are *imp* `firstprivate`, so by
default the reduced value from an `acc parallel loop` is not visible
after the `acc parallel loop`.  The OpenACC technical committee is
working to address this and other confusing points in the
specification of reductions, and Clacc's current mapping represents
our attempt to match the intended behavior.

Unmappable Features
-------------------

It might prove to be impossible to map some OpenACC features to
standard OpenMP.  For such features, our plan is to map to OpenMP
language or runtime extensions, which we will implement as necessary.

When source-to-source translation (as opposed to normal full
compilation) is enabled, we will implement diagnostics to identify
uses of such features unless those diagnostics are inexact and prove
to have too many false positives.  In the worst cases, we would
identify such features at run time.

The following is a list of OpenACC features we have identified that
might not be possible to map to OpenMP, but we are still investigating
possible solutions:

* `vector_length` with a non-constant-expression argument because
  `simdlen`, to which `vector_length` is translated, requires a
  constant expression.  In the future, Clacc might support alternative
  mappings for partitioning types, either configured by the user or
  computed automatically.  If `acc loop vector` were mapped to `omp
  parallel for`, `vector_length` with a non-constant-expression
  argument would be possible.
* If a variable is gang-shared within an `acc parallel` due to, for
  example, a `copy` clause there, and if that variable is also
  involved in a gang reduction specified on a nested `acc loop`, that
  variable becomes gang-private throughout that `acc parallel` when
  translated to OpenMP, where the reduction must be specified at the
  level of the `acc parallel` (`omp target teams`):
    * This discrepancy is mostly relevant to accesses to that variable
      within that `acc parallel` before that `acc loop`.  Within that
      `acc parallel` after that `acc loop`, it's probably not
      reasonable to access the variable in either version because the
      reduction doesn't happen until the end of the `acc parallel`.
    * It's possible we could fix this by generating some other
      gang-reduced variable that replaces the original variable within
      the `acc loop gang`, but the original gang-shared variable
      remains elsewhere in the `acc parallel`.  The gang-reduced
      variable would be initialized as all its private copies are
      initialized (e.g., 1 in the case of `*`), and we would need some
      way to combine (just one multiply in the case of `*`) its
      reduced value back into the shared copy.  To declare the
      gang-reduced variable and combine it back into the gang-shared
      variable, perhaps we'd break `omp target teams` into two
      directives and add the additional code outside the `omp teams`.
    * Anyway, to get this right, we first have to understand exactly
      what OpenACC says about how a gang-shared variable interacts
      with multiple `acc loop` directives that have gang-reductions
      for that variable within a single `acc parallel`.  Does it
      correspond to the above behavior?  Experimenting with pgcc
      18.4-0, it doesn't seem to.  Actually, with -ta:tesla, it seems
      to do exactly what Clacc does now when there's no `copy` clause
      specified: there's a gang reduction implied on `acc parallel`,
      and the variable is gang-private within.
    * Because we have not yet implemented explicit or implicit `copy`
      clauses, and because OpenACC 2.6 only permits reductions for
      scalars, such a reduction variable will be `firstprivate` or
      `private` and thus gang-private, so this issue doesn't affect us
      yet.
* A gang reduction specified on an orphaned `acc loop` directive
  because the enclosing compute construct to which the reduction would
  normally be applied during translation is not statically visible.
* `acc loop` directive that observes `num_workers` and `vector_length`
  because the enclosing compute construct from which those clauses
  would normally be applied during translation is not statically
  visible.
* Multiple reference counters because OpenMP has just one reference
  counter.

C++ Issues
----------

* Restrictions for private and reduction clauses related to
  const-qualified types could be relaxed in the case of mutable
  fields.  The OpenMP implementation does this, as hinted by OpenMP
  5.0 sec. 2.19.1.1 phrase "with no mutable members".
